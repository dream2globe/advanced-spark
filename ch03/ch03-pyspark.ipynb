{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3\n",
    "\n",
    "## Referrence\n",
    "- ALS 알고리즘 설명 : https://ggoals.github.io/Spark_ALS_Algorithm_tuning/\n",
    "- Towards data science : https://towardsdatascience.com/build-recommendation-system-with-pyspark-using-alternating-least-squares-als-matrix-factorisation-ebe1ad2e7679\n",
    "- Spark tutorial : https://spark.apache.org/docs/latest/ml-collaborative-filtering.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://storage.googleapis.com/aas-data-sets/profiledata_06-May-2005.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar xvf ./data/profiledata_06-May-2005.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import logging\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "# from pytz import timezone\n",
    "# from pytz import utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXECUTOR_MEMORY = \"2g\"\n",
    "EXECUTOR_CORES = 2\n",
    "EXECUTORE_INSTANCES = 3\n",
    "DRIVER_MEMORY = \"1g\"\n",
    "DRIVER_MAX_RESULT_SIZE = \"1g\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.eventLog.enabled', 'true'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS',\n",
       "  'desktop'),\n",
       " ('spark.executor.instances', '3'),\n",
       " ('spark.driver.extraJavaOptions',\n",
       "  '\"-Dio.netty.tryReflectionSetAccessible=true\"'),\n",
       " ('spark.driver.appUIAddress', 'http://192.168.0.2:4040'),\n",
       " ('spark.history.ui.port', '18081'),\n",
       " ('spark.driver.memory', '1g'),\n",
       " ('spark.driver.host', '192.168.0.2'),\n",
       " ('spark.serializer', 'org.apache.spark.serializer.KryoSerializer'),\n",
       " ('spark.ui.proxyBase', '/proxy/application_1610963608187_0002'),\n",
       " ('spark.executor.extraJavaOptions',\n",
       "  '\"-Dio.netty.tryReflectionSetAccessible=true\"'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES',\n",
       "  'http://desktop:8088/proxy/application_1610963608187_0002'),\n",
       " ('spark.app.name', 'Advanced analytics with SPARK - Chapter 3'),\n",
       " ('spark.history.provider',\n",
       "  'org.apache.spark.deploy.history.FsHistoryProvider'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.history.fs.update.interval', '10s'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.history.fs.logDirectory', 'hdfs://desktop:9000/spark-logs'),\n",
       " ('spark.ui.filters',\n",
       "  'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter'),\n",
       " ('spark.eventLog.dir', 'hdfs://desktop:9000/spark-logs'),\n",
       " ('spark.executor.memory', '2g'),\n",
       " ('spark.driver.port', '35151'),\n",
       " ('spark.kryoserializer.buffer.max', '1024m'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.executorEnv.PYTHONPATH',\n",
       "  '{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.9-src.zip'),\n",
       " ('spark.driver.maxResultSize', '1g'),\n",
       " ('spark.executor.cores', '2'),\n",
       " ('spark.app.id', 'application_1610963608187_0002'),\n",
       " ('spark.master', 'yarn'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.yarn.isPython', 'true'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(f\"Advanced analytics with SPARK - Chapter 3\")\n",
    "    .master(\"yarn\")\n",
    "    .config(\"spark.executor.memory\", EXECUTOR_MEMORY)\n",
    "    .config(\"spark.executor.cores\", EXECUTOR_CORES)\n",
    "    .config(\"spark.executor.instances\", EXECUTORE_INSTANCES)\n",
    "    .config(\"spark.driver.memory\", DRIVER_MEMORY)\n",
    "    .config(\"spark.driver.maxResultSize\", DRIVER_MAX_RESULT_SIZE)\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"1024m\")\n",
    "#     .config(\"spark.sql.warehouse.dir\", \"/user/bigdata/members/shyeon/advanced-spark/data\")\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music Listening Dataset\n",
      "Audioscrobbler.com\n",
      "6 May 2005\n",
      "--------------------------------\n",
      "\n",
      "This data set contains profiles for around 150,000 real people\n",
      "The dataset lists the artists each person listens to, and a counter\n",
      "indicating how many times each user played each artist\n",
      "\n",
      "The dataset is continually growing; at the time of writing (6 May 2005) \n",
      "Audioscrobbler is receiving around 2 million song submissions per day\n",
      "\n",
      "We may produce additional/extended data dumps if anyone is interested \n",
      "in experimenting with the data. \n",
      "\n",
      "Please let us know if you do anything useful with this data, we're always\n",
      "up for new ways to visualize it or analyse/cluster it etc :)\n",
      "\n",
      "\n",
      "License\n",
      "-------\n",
      "\n",
      "This data is made available under the following Creative Commons license:\n",
      "http://creativecommons.org/licenses/by-nc-sa/1.0/\n",
      "\n",
      "\n",
      "Files\n",
      "-----\n",
      "\n",
      "user_artist_data.txt\n",
      "    3 columns: userid artistid playcount\n",
      "\n",
      "artist_data.txt\n",
      "    2 columns: artistid artist_name\n",
      "\n",
      "artist_alias.txt\n",
      "    2 columns: badid, goodid\n",
      "    known incorrectly spelt artists and the correct artist id. \n",
      "    you can correct errors in user_artist_data as you read it in using this file\n",
      "    (we're not yet finished merging this data)\n",
      "    \n",
      "    \n",
      "Contact Info\n",
      "------------\n",
      "rj@audioscrobbler.com\n",
      "irc://irc.audioscrobbler.com/audioscrobbler\n"
     ]
    }
   ],
   "source": [
    "!cat /home/shyeon/workspace/apache-project/advanced-spark/data/ch03/README.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user_artist_data\n",
    "\n",
    "- empty space로 컬럼 구분\n",
    "- id, count 모두 integer type로 구성됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000002 1 55\n",
      "1000002 1000006 33\n",
      "1000002 1000007 8\n",
      "1000002 1000009 144\n",
      "1000002 1000010 314\n",
      "1000002 1000013 8\n",
      "1000002 1000014 42\n",
      "1000002 1000017 69\n",
      "1000002 1000024 329\n",
      "1000002 1000025 1\n"
     ]
    }
   ],
   "source": [
    "!head /home/shyeon/workspace/apache-project/advanced-spark/data/ch03/user_artist_data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+\n",
      "| userid|artistid|playcount|\n",
      "+-------+--------+---------+\n",
      "|1000002|       1|       55|\n",
      "|1000002| 1000006|       33|\n",
      "|1000002| 1000007|        8|\n",
      "|1000002| 1000009|      144|\n",
      "|1000002| 1000010|      314|\n",
      "+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_artist_schema = T.StructType([\n",
    "    T.StructField(\"userid\", T.IntegerType(), True),\n",
    "    T.StructField(\"artistid\", T.IntegerType(), True),\n",
    "    T.StructField(\"playcount\", T.IntegerType(), True),\n",
    "])\n",
    "\n",
    "user_artist_df = (\n",
    "    spark\n",
    "    .read.format(\"csv\")\n",
    "    .option(\"header\", False)\n",
    "    .option(\"sep\", \" \")\n",
    "    .schema(user_artist_schema)\n",
    "    .load(\"/data/advanced-spark/ch03/user_artist_data.txt\")\n",
    ")\n",
    "\n",
    "user_artist_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### artist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1134999\t06Crazy Life\n",
      "6821360\tPang Nakarin\n",
      "10113088\tTerfel, Bartoli- Mozart: Don\n",
      "10151459\tThe Flaming Sidebur\n",
      "6826647\tBodenstandig 3000\n",
      "10186265\tJota Quest e Ivete Sangalo\n",
      "6828986\tToto_XX (1977\n",
      "10236364\tU.S Bombs -\n",
      "1135000\tartist formaly know as Mat\n",
      "10299728\tKassierer - Musik für beide Ohren\n"
     ]
    }
   ],
   "source": [
    "!head /home/shyeon/workspace/apache-project/advanced-spark/data/ch03/artist_data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------------------+\n",
      "|artistid|artistname                  |\n",
      "+--------+----------------------------+\n",
      "|1134999 |06Crazy Life                |\n",
      "|6821360 |Pang Nakarin                |\n",
      "|10113088|Terfel, Bartoli- Mozart: Don|\n",
      "|10151459|The Flaming Sidebur         |\n",
      "|6826647 |Bodenstandig 3000           |\n",
      "+--------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artist_schema = T.StructType([\n",
    "    T.StructField(\"artistid\", T.IntegerType(), True),\n",
    "    T.StructField(\"artistname\", T.StringType(), True),\n",
    "])\n",
    "\n",
    "artist_df = (\n",
    "    spark\n",
    "    .read.format(\"csv\")\n",
    "    .option(\"header\", False)\n",
    "    .option(\"sep\", \"\\t\")\n",
    "    .schema(artist_schema)\n",
    "    .load(\"/data/advanced-spark/ch03/artist_data.txt\")\n",
    ")\n",
    "\n",
    "artist_df.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### artist_alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1092764\t1000311\n",
      "1095122\t1000557\n",
      "6708070\t1007267\n",
      "10088054\t1042317\n",
      "1195917\t1042317\n",
      "1112006\t1000557\n",
      "1187350\t1294511\n",
      "1116694\t1327092\n",
      "6793225\t1042317\n",
      "1079959\t1000557\n"
     ]
    }
   ],
   "source": [
    "!head /home/shyeon/workspace/apache-project/advanced-spark/data/ch03/artist_alias.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|badid   |goodid |\n",
      "+--------+-------+\n",
      "|1092764 |1000311|\n",
      "|1095122 |1000557|\n",
      "|6708070 |1007267|\n",
      "|10088054|1042317|\n",
      "|1195917 |1042317|\n",
      "+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artist_alias_schema = T.StructType([\n",
    "    T.StructField(\"badid\", T.IntegerType(), True),\n",
    "    T.StructField(\"goodid\", T.IntegerType(), True),\n",
    "])\n",
    "\n",
    "artist_alias_df = (\n",
    "    spark\n",
    "    .read.format(\"csv\")\n",
    "    .option(\"header\", False)\n",
    "    .option(\"sep\", \"\\t\")\n",
    "    .schema(artist_alias_schema)\n",
    "    .load(\"/data/advanced-spark/ch03/artist_alias.txt\")\n",
    ")\n",
    "\n",
    "artist_alias_df.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- user_artist_df의 artistid 필드를 artist_df를 참조하여 badid를 goodid로 교체\n",
    "- broadcase 함수 적용\n",
    "- cache 함수를 적용하면 Storage 탭에서 메모리 사용량을 알 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_artist_df = (\n",
    "    user_artist_df\n",
    "    .join(F.broadcast(artist_alias_df), user_artist_df.artistid == artist_alias_df.badid, \"left\")\n",
    "    .withColumn(\"artistid\", F.when(F.col(\"badid\").isNull(), F.col(\"artistid\")).otherwise(F.col(\"goodid\")))\n",
    "    .where(F.col(\"badid\").isNotNull())\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+-------+-------+\n",
      "| userid|artistid|playcount|  badid| goodid|\n",
      "+-------+--------+---------+-------+-------+\n",
      "|1000002| 1000518|       89|1000434|1000518|\n",
      "|1000002| 1001514|        1|1000762|1001514|\n",
      "|1000002|     721|        1|1001220|    721|\n",
      "|1000002| 1034635|        5|1001410|1034635|\n",
      "|1000002|    3066|        1|1002498|   3066|\n",
      "|1000002| 6691692|        1|1003377|6691692|\n",
      "|1000002| 1237611|        1|1003633|1237611|\n",
      "|1000002| 1034635|        4|1006102|1034635|\n",
      "|1000002| 1001172|        1|1007652|1001172|\n",
      "|1000002| 1008391|        2|1010219|1008391|\n",
      "|1000002| 2006683|        1|1017405|2006683|\n",
      "|1000002| 1000840|        2|1059598|1000840|\n",
      "|1000002| 2058809|        2|   3197|2058809|\n",
      "|1000002| 1066440|       76|   5702|1066440|\n",
      "|1000002| 2003588|        2|    709|2003588|\n",
      "|1000019| 1239413|        1|1000287|1239413|\n",
      "|1000019| 2001739|        1|1000586|2001739|\n",
      "|1000019| 1247540|        6|1000943|1247540|\n",
      "|1000019| 1049809|        4|1001379|1049809|\n",
      "|1000019|    4377|        1|1002143|   4377|\n",
      "+-------+--------+---------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_user_artist_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model (Spark Tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS \n",
    "\n",
    "als = ALS(seed=42,\n",
    "          implicitPrefs=False, # Explicit vs Implicit\n",
    "          rank=10,\n",
    "          regParam=0.01,\n",
    "          alpha=1.0,\n",
    "          maxIter=5,\n",
    "          userCol=\"userid\", itemCol=\"artistid\", ratingCol=\"playcount\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "\n",
    "(train, test) = new_user_artist_df.randomSplit([0.8, 0.2])\n",
    "als_model = als.fit(new_user_artist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 15.359224393679686\n"
     ]
    }
   ],
   "source": [
    "predictions = als_model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"playcount\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = als_model.recommendForAllUsers(10)\n",
    "# Generate top 10 user recommendations for each movie\n",
    "movieRecs = als_model.recommendForAllItems(10)\n",
    "\n",
    "# Show recomeadations\n",
    "# userRecs.show(n=10, truncate=False)\n",
    "# movieRecs.show(n=10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|userid |\n",
      "+-------+\n",
      "|2130958|\n",
      "|2131738|\n",
      "|2132906|\n",
      "+-------+\n",
      "\n",
      "+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|userid |recommendations                                                                                                                                                                                                            |\n",
      "+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1000484|[[1279475, 509.51498], [4423, 285.59818], [1254487, 198.77986], [1002128, 174.14009], [2134114, 156.99306], [1308254, 120.996124], [1061239, 114.24648], [1086065, 110.887115], [1240919, 110.20026], [1082068, 110.14881]]|\n",
      "|1000584|[[6899306, 180.5835], [1279475, 120.61687], [1123047, 113.81703], [1280614, 112.68537], [1313603, 97.26634], [1055411, 94.64791], [1101322, 92.81742], [6846841, 79.280426], [10073912, 78.5072], [4371, 77.58006]]        |\n",
      "|1000509|[[1017916, 633.2707], [2043183, 617.6902], [6799188, 440.63922], [1101322, 329.008], [1001017, 271.35806], [2036225, 232.64966], [1248506, 231.83801], [7034181, 212.84283], [7018959, 210.13376], [1237708, 204.71098]]   |\n",
      "+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate top 10 movie recommendations for a specified set of users\n",
    "users = new_user_artist_df.select(als.getUserCol()).distinct().limit(3)\n",
    "userSubsetRecs = als_model.recommendForUserSubset(users, 10)\n",
    "\n",
    "users.show(n=3, truncate=False)\n",
    "userSubsetRecs.show(n=3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top 10 user recommendations for a specified set of movies\n",
    "movies = new_user_artist_df.select(als.getItemCol()).distinct().limit(3)\n",
    "movieSubSetRecs = als_model.recommendForItemSubset(movies, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|artistid|\n",
      "+--------+\n",
      "|6603174 |\n",
      "|6617623 |\n",
      "|2281438 |\n",
      "+--------+\n",
      "\n",
      "+--------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|artistid|recommendations                                                                                                                                                                                                          |\n",
      "+--------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|6603174 |[[2027150, 628.6284], [1073616, 425.4464], [1036787, 351.50726], [2088690, 345.38846], [1058675, 286.80307], [2213427, 240.12823], [2208970, 238.79904], [1031723, 225.10951], [1077099, 221.30304], [1060553, 206.8548]]|\n",
      "|2281438 |[[1059592, 1823.4567], [1070274, 1216.2745], [1009926, 855.8217], [1073616, 824.9633], [2008815, 655.1449], [2055013, 560.167], [1070204, 502.3236], [2007381, 399.23776], [2064988, 394.85437], [1058675, 381.27197]]   |\n",
      "|6617623 |[[1070274, 3187.4922], [1073616, 2755.4111], [2222067, 2301.734], [1059592, 2065.629], [1051417, 1605.5999], [1043990, 1580.5795], [2064988, 1485.5472], [2008815, 1450.3071], [1064240, 1399.2115], [1064168, 1318.429]]|\n",
      "+--------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.show(n=3, truncate=False)\n",
    "movieSubSetRecs.show(n=3, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model (Text Book)                                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------------------------------------------------------------------------------------------------------------+\n",
      "|id |features                                                                                                                          |\n",
      "+---+----------------------------------------------------------------------------------------------------------------------------------+\n",
      "|90 |[-0.028082298, 7.6310494E-4, 0.24914232, -0.55676687, -0.13148633, -0.31975958, 4.7636876E-4, -0.64081705, 0.6159623, -0.57702804]|\n",
      "+---+----------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "als_model.userFactors.show(1, truncate=False) # Rank 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------------------------+\n",
      "|artistid|artistname                        |\n",
      "+--------+----------------------------------+\n",
      "|1302232 |郭富城                            |\n",
      "|1020    |The Dave Brubeck Quartet          |\n",
      "|1328360 |鄧麗君                            |\n",
      "|1034635 |[unknown]                         |\n",
      "|1338195 |山崎まさよし                      |\n",
      "|6796568 |Les Petits Chanteurs de Saint-Marc|\n",
      "|9988765 |伊藤多喜雄                        |\n",
      "|1300816 |相川七瀬                          |\n",
      "|1003579 |LeAnn Rimes                       |\n",
      "|1280437 |倉木麻衣                          |\n",
      "|1345189 |米米CLUB                          |\n",
      "|1349540 |渡辺美里                          |\n",
      "|3066    |Nat King Cole                     |\n",
      "|1029324 |TM Network                        |\n",
      "|1020059 |Young M.C.                        |\n",
      "|1230410 |Billy Paul Williams               |\n",
      "|1300525 |氣志團                            |\n",
      "|2061677 |渡辺香津美                        |\n",
      "|1266817 |Stan Getz & João Gilberto         |\n",
      "|1028104 |Intenso Project                   |\n",
      "|2003588 |KoЯn                              |\n",
      "|1261516 |The Bobby Fuller Four             |\n",
      "|1271892 |Zigo                              |\n",
      "|2007793 |Luiz Bonfá                        |\n",
      "|1330911 |大黒摩季                          |\n",
      "|1328587 |木村弓                            |\n",
      "|1307741 |少年隊                            |\n",
      "|2065806 |柏原芳恵                          |\n",
      "|6834961 |大森俊之                          |\n",
      "|1235439 |The Murmurs                       |\n",
      "+--------+----------------------------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userID = 1004666\n",
    "\n",
    "existing_artist_ids = (\n",
    "    new_user_artist_df.where(F.col(\"userid\") == userID)\n",
    "    .select(F.col(\"artistid\").cast(T.IntegerType()))\n",
    "    .collect()\n",
    ")\n",
    "existing_artist_ids = [row.artistid for row in existing_artist_ids]\n",
    "\n",
    "artist_df.where(F.col(\"artistid\").isin(existing_artist_ids)).show(n=30, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|artistid|prediction|\n",
      "+--------+----------+\n",
      "|    4423| 488.04785|\n",
      "| 1279475| 458.93823|\n",
      "| 2134114|  413.4322|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def makeRecomendations(model, userid, howmany):\n",
    "    to_recommend = (\n",
    "        model.itemFactors.select(F.col(\"id\").alias(\"artistid\"))\n",
    "        .withColumn(\"userid\", F.lit(userid))\n",
    "    )\n",
    "\n",
    "    return model.transform(to_recommend).select(\"artistid\", \"prediction\").orderBy(F.col(\"prediction\").desc()).limit(howmany)\n",
    "\n",
    "recomendation = makeRecomendations(als_model, userID, 3)\n",
    "recomendation.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[artistid: int, prediction: float]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model (towards data science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required functions\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Create ALS model\n",
    "als = ALS(\n",
    "         userCol=\"userid\", \n",
    "         itemCol=\"artistid\",\n",
    "         ratingCol=\"playcount\", \n",
    "         nonnegative = True, \n",
    "         implicitPrefs = False,\n",
    "         coldStartStrategy=\"drop\"\n",
    ")\n",
    "\n",
    "# Add hyperparameters and their respective values to param_grid\n",
    "param_grid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(als.rank, [5, 30])\n",
    "    .addGrid(als.regParam, [4.0, 0.0001])\n",
    "    .addGrid(als.alpha, [1.0, 40.0])    \n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Define evaluator as RMSE and print length of evaluator\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", \n",
    "    labelCol=\"playcount\", \n",
    "    predictionCol=\"prediction\") \n",
    "\n",
    "# Build cross validation using CrossValidator\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit cross validator to the 'train' dataset\n",
    "model = cv.fit(train)\n",
    "\n",
    "# Extract best model from the cv model above\n",
    "best_model = model.bestModel\n",
    "\n",
    "# View the predictions\n",
    "test_predictions = best_model.transform(test)\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)\n",
    "\n",
    "print(\"**Best Model**\")\n",
    "print(\"  Rank:\", best_model._java_obj.parent().getRank())\n",
    "print(\"  MaxIter:\", best_model._java_obj.parent().getMaxIter())\n",
    "print(\"  RegParam:\", best_model._java_obj.parent().getRegParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate n Recommendations for all users\n",
    "recommendations = best_model.recommendForAllUsers(5)\n",
    "recommendations.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrecommendations = recommendations\\\n",
    "    .withColumn(\"rec_exp\", F.explode(\"recommendations\"))\\\n",
    "    .select(\"userid\", \"rec_exp.artistid\", \"rec_exp.rating\")\n",
    "    \n",
    "nrecommendations.limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction vs Real Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrecommendations.join(artist_df, on=\"artistid\").filter('userid = 1000190').sort(F.col(\"rating\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    new_user_artist_df.select(\"userid\", \"artistid\", \"playcount\")\n",
    "    .join(artist_df, on=\"artistid\")\n",
    "    .filter('userid = 1000190')\n",
    "    .sort(F.col(\"playcount\").desc())\n",
    ").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
